# Practical Exercise 5: Place context analysis using machine learning

In this practical exercise, you are expected to use Natural Language Processing, a typical machine learning algorithm, to explore a book author's sense of place about Seattle. 


## 1.  Environment Setup

This execerise is designed to in a Python programming environment, Before conducting the analysis, we need to install a couple of python libraries. Please execute the following line on command prompt or terminal.


```powershell
pip install PyMuPDF, tika, gensim, spacy, nltk, wordcloud
```

## 2. Reading and Preprocessing PDF files

<img src="img/gbook.png" width="250px" align="right" /> In this section, we need to read all the pdf files of the book *Gay Seattle*, please download all the pdf files from the Google drive and store them in the folder named as `gay-seattle` under the `assets` folder. After migrating files, we need to delete the front page of each pdf file since this page, containing the meta data of the pdf file, is irrelevant to the maintext of this book. Then, the python script recognizes the text of each pdf file using a python library `pika`. In the end, all the text will be stored in an text file named `gay-seattle.txt`.


## 3. Making a Wordcloud




## 4. Spatial dimension of sense of place


## 5. Contextual dimension

## Deliverable



## References
* Thrush, C., 2017. Native Seattle: Histories from the crossing-over place. Accessed from https://muse.jhu.edu/book/10411. University of Washington Press.

* Atkins, G., 2011. Gay Seattle: Stories of exile and belonging. Accessed from https://muse.jhu.edu/book/40703. University of Washington Press.
